# Supporting Code for Machine Learning Course

This is a project with supporting code for Machine Learning course based on MIT 6.036 course and Microsoft ML for beginners course.

## Courses

- MIT 6.036 ML Course: [https://openlearninglibrary.mit.edu/courses/course-v1:MITx+6.036+1T2019/course/](https://openlearninglibrary.mit.edu/courses/course-v1:MITx+6.036+1T2019/course/)
- Microsoft ML for Beginners Course: [https://github.com/microsoft/ML-For-Beginners](https://github.com/microsoft/ML-For-Beginners)

## Video Lessons

1. Introduction to Machine Learning Teach by Doing: [https://lnkd.in/gqN2PMX5](https://lnkd.in/gqN2PMX5)
2. What is Machine Learning? History of Machine Learning: [https://lnkd.in/gvpNSAKh](https://lnkd.in/gvpNSAKh)
3. Types of ML Models: [https://lnkd.in/gSy2mChM](https://lnkd.in/gSy2mChM)
4. 6 steps of any ML project: [https://lnkd.in/ggCGchPQ](https://lnkd.in/ggCGchPQ)
5. Install Python and VSCode and run your first code: [https://lnkd.in/gyic7J7b](https://lnkd.in/gyic7J7b)
6. Linear Classifiers Part 1: [https://lnkd.in/gYdfD97D](https://lnkd.in/gYdfD97D)
7. Linear Classifiers Part 2: [https://lnkd.in/gac_z-G8](https://lnkd.in/gac_z-G8)
8. Jupyter Notebook, Numpy and Scikit-Learn: [https://lnkd.in/gWRaC_tB](https://lnkd.in/gWRaC_tB)
9. Running the Random Linear Classifier Algorithm in Python: [https://lnkd.in/g5HacbFC](https://lnkd.in/g5HacbFC)
10. The oldest ML model - Perceptron: [https://lnkd.in/gpce6uFt](https://lnkd.in/gpce6uFt)
11. Coding the Perceptron: [https://lnkd.in/gmz-XjNK](https://lnkd.in/gmz-XjNK)
12. Perceptron Convergence Theorem: [https://lnkd.in/gmz-XjNK](https://lnkd.in/gmz-XjNK)
13. Magic of features in Machine Learning: [https://lnkd.in/gCeDRb3g](https://lnkd.in/gCeDRb3g)
14. One hot encoding: [https://lnkd.in/g3WfRQGQ](https://lnkd.in/g3WfRQGQ)
15. Logistic Regression Part 1: [https://lnkd.in/gTgZAAZn](https://lnkd.in/gTgZAAZn)
16. Cross Entropy Loss: [https://lnkd.in/g3Ywg_2p](https://lnkd.in/g3Ywg_2p)
17. How gradient descent works: [https://lnkd.in/gKBAsazF](https://lnkd.in/gKBAsazF)
18. Logistic Regression from scratch in Python: [https://lnkd.in/g8iZh27P](https://lnkd.in/g8iZh27P)
19. Introduction to Regularization: [https://lnkd.in/gjM9pVw2](https://lnkd.in/gjM9pVw2)
20. Implementing Regularization in Python: [https://lnkd.in/gRnSK4v4](https://lnkd.in/gRnSK4v4)
21. Linear Regression Introduction: [https://lnkd.in/gPYtSPJ9](https://lnkd.in/gPYtSPJ9)
22. Ordinary Least Squares step by step implementation: [https://lnkd.in/gnWQdgNy](https://lnkd.in/gnWQdgNy)
23. Ridge regression fundamentals and intuition: [https://lnkd.in/gE5M-CSM](https://lnkd.in/gE5M-CSM)
24. Regression recap for interviews: [https://lnkd.in/gNBWzzWv](https://lnkd.in/gNBWzzWv)
25. Neural network architecture in 30 minutes: [https://lnkd.in/g7qSrkxG](https://lnkd.in/g7qSrkxG)
26. Backpropagation intuition: [https://lnkd.in/gAmBARHm](https://lnkd.in/gAmBARHm)
27. Neural network activation functions: [https://lnkd.in/gqrC3zDP](https://lnkd.in/gqrC3zDP)
28. Momentum in gradient descent: [https://lnkd.in/g3M4qhbP](https://lnkd.in/g3M4qhbP)
29. Hands on neural network training in Python: [https://lnkd.in/gz-fTBxs](https://lnkd.in/gz-fTBxs)